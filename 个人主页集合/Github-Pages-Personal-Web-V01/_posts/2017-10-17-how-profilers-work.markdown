---
layout:     post
title:      "Profilers是如何工作的（性能分析器原理）"
subtitle:   "How profilers work"
date:       2017-10-17
author:     "QQF"
header-img: "img/home-bg.png"
catalog: true
tags:
    - Python
---

# Profilers是如何工作的

Profilers是用于检查程序如何使用各种计算资源的工具。 它们在程序运行时测量各种程序特性（内存使用，函数调用的持续时间等），并汇总收集的数据以创建可帮助程序优化的报告。

在这篇文章中，我们将构建两个简单的Profilers来测量函数调用时间（下面简称“Profilers”），但是以稍微不同的方式解决这个问题。 这篇文章也出现在我在vprof工作时做的各种笔记，我希望它对你有用。

Python（更准确的说是CPython）用于本文中的所有代码，因为它为开发人员提供了很好的工具，但是这里讨论的概念可以很容易地应用于其他主流的高级编程语言。

我们将考虑两种类型的Profilers：确定性和统计性分析器。

确定性分析器记录所有函数调用和返回的精确时间，然后处理收集的数据以确定函数调用的持续时间和其他重要参数。 虽然此方法具有更高的精度，但它增加了显著的开销（特别是对小函数），并且程序在分析时运行速度较慢。

统计分析器定期拍摄正在运行的程序的快照，并推断在哪里花费时间。 这种方法的开销比确定性分析器少并且程序几乎全速运行，但通常精度较低，因为收集的分析资料只提供了一个时间花费统计近似值。
这里是我们将使用我们的分析器检查的代码

![img](/img/in-post/2017-10-17-how-profilers-work/01.png)

该代码产生N个素数，其中sum\_of\_digits 是偶数。 虽然代码远不是完美算法，但是它很简单，适合我们的需求。

# 确定性分析器

也许最简单的方法来测量我们的代码的执行时间是使用Python的内置time.time()函数

![img](/img/in-post/2017-10-17-how-profilers-work/02.png)

如果我们运行它，我们会得到这些：

![img](/img/in-post/2017-10-17-how-profilers-work/03.png)

看起来不错。 现在我们知道get_primes需要的调用时间。 但是有一个问题 - 我们想看到sum\_of\_digits和is\_prime调用的时间，以确定瓶颈。

让我们改进我们的方法:

![img](/img/in-post/2017-10-17-how-profilers-work/04.png)

这里我们使用熟知的Python技术 - 分析装饰器。

对于那些不熟悉Python装饰器的人 - @decorator只是func = decorator（func）的一个快捷方式，它允许改变Python函数（在这里你可以找到很好的Python装饰器的介绍）。

然后我们需要用新的分析装饰器来封装我们的函数

![img](/img/in-post/2017-10-17-how-profilers-work/05.png)

并再次运行我们的代码

![img](/img/in-post/2017-10-17-how-profilers-work/06.png)

输出为

![img](/img/in-post/2017-10-17-how-profilers-work/07.png)

不完全是这样的。 我们可以看到单独的调用时间，但是，由于有这么多的函数调用，我们看不到大图。

此外，您可能会注意到，现在总时间更大，因为我们引入了分析器开销 - 每个包装的函数调用time.time() 两次，做一次减法，然后字符串格式化并将结果字符串打印到stdout。

我们的分析装饰器可以改进。 如果我们想查看概述，则不需要打印每个函数调用的调用时间。 代替打印调用时间，让我们存储函数名称，它是每个函数调用后的调用者名称和累积调用时间。

![img](/img/in-post/2017-10-17-how-profilers-work/08.png)

我们用defaultdict中的累积函数调用时间来代替print调用，这允许我们存储每个调用者的累积调用时间。

改进装饰器的包装功能

![img](/img/in-post/2017-10-17-how-profilers-work/09.png)

并再次运行我们的代码

![img](/img/in-post/2017-10-17-how-profilers-work/10.png)

![img](/img/in-post/2017-10-17-how-profilers-work/11.png)

统计信息存储在stats变量中。 让我们打印它们

![img](/img/in-post/2017-10-17-how-profilers-work/12.png)

即使从原始统计信息中，我们也可以看到调用is_prime花费了大部分时间。

最后，让我们总结收集的统计数据和打印漂亮的报告

![img](/img/in-post/2017-10-17-how-profilers-work/13.png)

![img](/img/in-post/2017-10-17-how-profilers-work/14.png)

现在我们看到大多数时间花在is\_prime函数内部，如果我们想提高整体get\_primes性能，is\_prime是第一个优化候选。

我们的确定性分析器的精度由这些因素决定：

1. 定时器精度。 没有测量可以比底层定时器（〜1毫秒）更准确。

2. 时间的测量不是即时的，并且在退出用户代码和测量时间的时间之间存在延迟，然后再次执行用户代码。 不执行大量计算的小函数特别容易出现这种错误，因为它倾向于累加。 通过校准分析器可以减少此错误。
注意：Python为写入分析器提供了sys.settrace() 钩子，因此我建议将其用于所有重要的用例。

# 统计性分析器

如上所述，统计分析器通过以规律的间隔对调用栈进行抽样来操作。 为了做到这一点，我们需要定义一个函数，它将调用堆栈抽样，然后安排这个函数定期执行。 Python signal模块将帮助我们。

这里是这种方法的代码

![img](/img/in-post/2017-10-17-how-profilers-work/15.png)

sample_stack回调是signal处理程序。 它存储当前调用堆栈名称以及调用堆栈被采样的次数，并计划发出新信号的定时器。 我们使用ITIMER_PROF，因为它在进程执行时和系统代表进程执行时减少底层定时器。 ITIMER_PROF在到期时发出SIGPROF。 其他代码只设置简单的统计分析器并测量总运行时间。

在我们运行代码和打印stats变量后，我们将看到这个

![img](/img/in-post/2017-10-17-how-profilers-work/16.png)

我们可以看到get_primes捕获了312个样本，is_prime - 876个样本和sum of digits - 只有1个样本。 由于大多数样本属于is_prime函数，我们可以假设大部分时间都是花费在这里。 我们将使用总样本数（312 + 876 + 1 = 1189）进行下面的计算。

让我们总结统计分析器的统计信息，并将其与确定性分析器的统计信息进行比较

![img](/img/in-post/2017-10-17-how-profilers-work/17.png)

![img](/img/in-post/2017-10-17-how-profilers-work/18.png)

首先，我们可以观察到总运行时间小于确定性分析器，这可以归因于统计分析器具有较少开销的事实。此外，is\_prime（〜73.7％）的百分比低于确定性分析器（〜99％）。这是因为统计分析器的结果数据是一个近似值。此外，如果我们运行分析器多次，我们可以得到相当不同的结果（70-99％）。这意味着在做出优化决策时应该考虑较低的精度。然而，这些结果可以帮助我们发现代码中的瓶颈。

# 总结

我们为Python构建了简单的确定性和统计分析器。分析器测量函数调用时间，但列出的方法可以应用于测量其他程序特性，如内存使用。这里讨论的概念也适用于其他主流的高级编程语言。